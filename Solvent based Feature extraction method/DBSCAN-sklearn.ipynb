{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DBSCAN: Density-Based Spatial Clustering of Applications with Noise\n",
    "\"\"\"\n",
    "\n",
    "# Author: Robert Layton <robertlayton@gmail.com>\n",
    "#         Joel Nothman <joel.nothman@gmail.com>\n",
    "#         Lars Buitinck\n",
    "#\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import warnings\n",
    "from numbers import Integral, Real\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from ..metrics.pairwise import _VALID_METRICS\n",
    "from ..base import BaseEstimator, ClusterMixin\n",
    "from ..utils.validation import _check_sample_weight\n",
    "from ..utils._param_validation import Interval, StrOptions\n",
    "from ..neighbors import NearestNeighbors\n",
    "from ._dbscan_inner import dbscan_inner\n",
    "\n",
    "\n",
    "def dbscan(\n",
    "    X,\n",
    "    eps=0.5,\n",
    "    *,\n",
    "    min_samples=5,\n",
    "    metric=\"minkowski\",\n",
    "    metric_params=None,\n",
    "    algorithm=\"auto\",\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    sample_weight=None,\n",
    "    n_jobs=None,\n",
    "):\n",
    "    \"\"\"Perform DBSCAN clustering from vector array or distance matrix.\n",
    "    Read more in the :ref:`User Guide <dbscan>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse (CSR) matrix} of shape (n_samples, n_features) or \\\n",
    "            (n_samples, n_samples)\n",
    "        A feature array, or array of distances between samples if\n",
    "        ``metric='precomputed'``.\n",
    "    eps : float, default=0.5\n",
    "        The maximum distance between two samples for one to be considered\n",
    "        as in the neighborhood of the other. This is not a maximum bound\n",
    "        on the distances of points within a cluster. This is the most\n",
    "        important DBSCAN parameter to choose appropriately for your data set\n",
    "        and distance function.\n",
    "    min_samples : int, default=5\n",
    "        The number of samples (or total weight) in a neighborhood for a point\n",
    "        to be considered as a core point. This includes the point itself.\n",
    "    metric : str or callable, default='minkowski'\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string or callable, it must be one of\n",
    "        the options allowed by :func:`sklearn.metrics.pairwise_distances` for\n",
    "        its metric parameter.\n",
    "        If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
    "        must be square during fit.\n",
    "        X may be a :term:`sparse graph <sparse graph>`,\n",
    "        in which case only \"nonzero\" elements may be considered neighbors.\n",
    "    metric_params : dict, default=None\n",
    "        Additional keyword arguments for the metric function.\n",
    "        .. versionadded:: 0.19\n",
    "    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
    "        The algorithm to be used by the NearestNeighbors module\n",
    "        to compute pointwise distances and find nearest neighbors.\n",
    "        See NearestNeighbors module documentation for details.\n",
    "    leaf_size : int, default=30\n",
    "        Leaf size passed to BallTree or cKDTree. This can affect the speed\n",
    "        of the construction and query, as well as the memory required\n",
    "        to store the tree. The optimal value depends\n",
    "        on the nature of the problem.\n",
    "    p : float, default=2\n",
    "        The power of the Minkowski metric to be used to calculate distance\n",
    "        between points.\n",
    "    sample_weight : array-like of shape (n_samples,), default=None\n",
    "        Weight of each sample, such that a sample with a weight of at least\n",
    "        ``min_samples`` is by itself a core sample; a sample with negative\n",
    "        weight may inhibit its eps-neighbor from being core.\n",
    "        Note that weights are absolute, and default to 1.\n",
    "    n_jobs : int, default=None\n",
    "        The number of parallel jobs to run for neighbors search. ``None`` means\n",
    "        1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means\n",
    "        using all processors. See :term:`Glossary <n_jobs>` for more details.\n",
    "        If precomputed distance are used, parallel execution is not available\n",
    "        and thus n_jobs will have no effect.\n",
    "    Returns\n",
    "    -------\n",
    "    core_samples : ndarray of shape (n_core_samples,)\n",
    "        Indices of core samples.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        Cluster labels for each point.  Noisy samples are given the label -1.\n",
    "    See Also\n",
    "    --------\n",
    "    DBSCAN : An estimator interface for this clustering algorithm.\n",
    "    OPTICS : A similar estimator interface clustering at multiple values of\n",
    "        eps. Our implementation is optimized for memory usage.\n",
    "    Notes\n",
    "    -----\n",
    "    For an example, see :ref:`examples/cluster/plot_dbscan.py\n",
    "    <sphx_glr_auto_examples_cluster_plot_dbscan.py>`.\n",
    "    This implementation bulk-computes all neighborhood queries, which increases\n",
    "    the memory complexity to O(n.d) where d is the average number of neighbors,\n",
    "    while original DBSCAN had memory complexity O(n). It may attract a higher\n",
    "    memory complexity when querying these nearest neighborhoods, depending\n",
    "    on the ``algorithm``.\n",
    "    One way to avoid the query complexity is to pre-compute sparse\n",
    "    neighborhoods in chunks using\n",
    "    :func:`NearestNeighbors.radius_neighbors_graph\n",
    "    <sklearn.neighbors.NearestNeighbors.radius_neighbors_graph>` with\n",
    "    ``mode='distance'``, then using ``metric='precomputed'`` here.\n",
    "    Another way to reduce memory and computation time is to remove\n",
    "    (near-)duplicate points and use ``sample_weight`` instead.\n",
    "    :func:`cluster.optics <sklearn.cluster.optics>` provides a similar\n",
    "    clustering with lower memory usage.\n",
    "    References\n",
    "    ----------\n",
    "    Ester, M., H. P. Kriegel, J. Sander, and X. Xu, `\"A Density-Based\n",
    "    Algorithm for Discovering Clusters in Large Spatial Databases with Noise\"\n",
    "    <https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf>`_.\n",
    "    In: Proceedings of the 2nd International Conference on Knowledge Discovery\n",
    "    and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996\n",
    "    Schubert, E., Sander, J., Ester, M., Kriegel, H. P., & Xu, X. (2017).\n",
    "    :doi:`\"DBSCAN revisited, revisited: why and how you should (still) use DBSCAN.\"\n",
    "    <10.1145/3068335>`\n",
    "    ACM Transactions on Database Systems (TODS), 42(3), 19.\n",
    "    \"\"\"\n",
    "\n",
    "    est = DBSCAN(\n",
    "        eps=eps,\n",
    "        min_samples=min_samples,\n",
    "        metric=metric,\n",
    "        metric_params=metric_params,\n",
    "        algorithm=algorithm,\n",
    "        leaf_size=leaf_size,\n",
    "        p=p,\n",
    "        n_jobs=n_jobs,\n",
    "    )\n",
    "    est.fit(X, sample_weight=sample_weight)\n",
    "    return est.core_sample_indices_, est.labels_\n",
    "\n",
    "\n",
    "class DBSCAN(ClusterMixin, BaseEstimator):\n",
    "    \"\"\"Perform DBSCAN clustering from vector array or distance matrix.\n",
    "    DBSCAN - Density-Based Spatial Clustering of Applications with Noise.\n",
    "    Finds core samples of high density and expands clusters from them.\n",
    "    Good for data which contains clusters of similar density.\n",
    "    Read more in the :ref:`User Guide <dbscan>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    eps : float, default=0.5\n",
    "        The maximum distance between two samples for one to be considered\n",
    "        as in the neighborhood of the other. This is not a maximum bound\n",
    "        on the distances of points within a cluster. This is the most\n",
    "        important DBSCAN parameter to choose appropriately for your data set\n",
    "        and distance function.\n",
    "    min_samples : int, default=5\n",
    "        The number of samples (or total weight) in a neighborhood for a point\n",
    "        to be considered as a core point. This includes the point itself.\n",
    "    metric : str, or callable, default='euclidean'\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string or callable, it must be one of\n",
    "        the options allowed by :func:`sklearn.metrics.pairwise_distances` for\n",
    "        its metric parameter.\n",
    "        If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
    "        must be square. X may be a :term:`sparse graph`, in which\n",
    "        case only \"nonzero\" elements may be considered neighbors for DBSCAN.\n",
    "        .. versionadded:: 0.17\n",
    "           metric *precomputed* to accept precomputed sparse matrix.\n",
    "    metric_params : dict, default=None\n",
    "        Additional keyword arguments for the metric function.\n",
    "        .. versionadded:: 0.19\n",
    "    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
    "        The algorithm to be used by the NearestNeighbors module\n",
    "        to compute pointwise distances and find nearest neighbors.\n",
    "        See NearestNeighbors module documentation for details.\n",
    "    leaf_size : int, default=30\n",
    "        Leaf size passed to BallTree or cKDTree. This can affect the speed\n",
    "        of the construction and query, as well as the memory required\n",
    "        to store the tree. The optimal value depends\n",
    "        on the nature of the problem.\n",
    "    p : float, default=None\n",
    "        The power of the Minkowski metric to be used to calculate distance\n",
    "        between points. If None, then ``p=2`` (equivalent to the Euclidean\n",
    "        distance).\n",
    "    n_jobs : int, default=None\n",
    "        The number of parallel jobs to run.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    Attributes\n",
    "    ----------\n",
    "    core_sample_indices_ : ndarray of shape (n_core_samples,)\n",
    "        Indices of core samples.\n",
    "    components_ : ndarray of shape (n_core_samples, n_features)\n",
    "        Copy of each core sample found by training.\n",
    "    labels_ : ndarray of shape (n_samples)\n",
    "        Cluster labels for each point in the dataset given to fit().\n",
    "        Noisy samples are given the label -1.\n",
    "    n_features_in_ : int\n",
    "        Number of features seen during :term:`fit`.\n",
    "        .. versionadded:: 0.24\n",
    "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
    "        Names of features seen during :term:`fit`. Defined only when `X`\n",
    "        has feature names that are all strings.\n",
    "        .. versionadded:: 1.0\n",
    "    See Also\n",
    "    --------\n",
    "    OPTICS : A similar clustering at multiple values of eps. Our implementation\n",
    "        is optimized for memory usage.\n",
    "    Notes\n",
    "    -----\n",
    "    For an example, see :ref:`examples/cluster/plot_dbscan.py\n",
    "    <sphx_glr_auto_examples_cluster_plot_dbscan.py>`.\n",
    "    This implementation bulk-computes all neighborhood queries, which increases\n",
    "    the memory complexity to O(n.d) where d is the average number of neighbors,\n",
    "    while original DBSCAN had memory complexity O(n). It may attract a higher\n",
    "    memory complexity when querying these nearest neighborhoods, depending\n",
    "    on the ``algorithm``.\n",
    "    One way to avoid the query complexity is to pre-compute sparse\n",
    "    neighborhoods in chunks using\n",
    "    :func:`NearestNeighbors.radius_neighbors_graph\n",
    "    <sklearn.neighbors.NearestNeighbors.radius_neighbors_graph>` with\n",
    "    ``mode='distance'``, then using ``metric='precomputed'`` here.\n",
    "    Another way to reduce memory and computation time is to remove\n",
    "    (near-)duplicate points and use ``sample_weight`` instead.\n",
    "    :class:`cluster.OPTICS` provides a similar clustering with lower memory\n",
    "    usage.\n",
    "    References\n",
    "    ----------\n",
    "    Ester, M., H. P. Kriegel, J. Sander, and X. Xu, `\"A Density-Based\n",
    "    Algorithm for Discovering Clusters in Large Spatial Databases with Noise\"\n",
    "    <https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf>`_.\n",
    "    In: Proceedings of the 2nd International Conference on Knowledge Discovery\n",
    "    and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996\n",
    "    Schubert, E., Sander, J., Ester, M., Kriegel, H. P., & Xu, X. (2017).\n",
    "    :doi:`\"DBSCAN revisited, revisited: why and how you should (still) use DBSCAN.\"\n",
    "    <10.1145/3068335>`\n",
    "    ACM Transactions on Database Systems (TODS), 42(3), 19.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.cluster import DBSCAN\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1, 2], [2, 2], [2, 3],\n",
    "    ...               [8, 7], [8, 8], [25, 80]])\n",
    "    >>> clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    "    >>> clustering.labels_\n",
    "    array([ 0,  0,  0,  1,  1, -1])\n",
    "    >>> clustering\n",
    "    DBSCAN(eps=3, min_samples=2)\n",
    "    \"\"\"\n",
    "\n",
    "    _parameter_constraints: dict = {\n",
    "        \"eps\": [Interval(Real, 0.0, None, closed=\"neither\")],\n",
    "        \"min_samples\": [Interval(Integral, 1, None, closed=\"left\")],\n",
    "        \"metric\": [\n",
    "            StrOptions(set(_VALID_METRICS) | {\"precomputed\"}),\n",
    "            callable,\n",
    "        ],\n",
    "        \"metric_params\": [dict, None],\n",
    "        \"algorithm\": [StrOptions({\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"})],\n",
    "        \"leaf_size\": [Interval(Integral, 1, None, closed=\"left\")],\n",
    "        \"p\": [Interval(Real, 0.0, None, closed=\"left\"), None],\n",
    "        \"n_jobs\": [Integral, None],\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eps=0.5,\n",
    "        *,\n",
    "        min_samples=5,\n",
    "        metric=\"euclidean\",\n",
    "        metric_params=None,\n",
    "        algorithm=\"auto\",\n",
    "        leaf_size=30,\n",
    "        p=None,\n",
    "        n_jobs=None,\n",
    "    ):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.metric = metric\n",
    "        self.metric_params = metric_params\n",
    "        self.algorithm = algorithm\n",
    "        self.leaf_size = leaf_size\n",
    "        self.p = p\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        \"\"\"Perform DBSCAN clustering from features, or distance matrix.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features), or \\\n",
    "            (n_samples, n_samples)\n",
    "            Training instances to cluster, or distances between instances if\n",
    "            ``metric='precomputed'``. If a sparse matrix is provided, it will\n",
    "            be converted into a sparse ``csr_matrix``.\n",
    "        y : Ignored\n",
    "            Not used, present here for API consistency by convention.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Weight of each sample, such that a sample with a weight of at least\n",
    "            ``min_samples`` is by itself a core sample; a sample with a\n",
    "            negative weight may inhibit its eps-neighbor from being core.\n",
    "            Note that weights are absolute, and default to 1.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns a fitted instance of self.\n",
    "        \"\"\"\n",
    "        self._validate_params()\n",
    "\n",
    "        X = self._validate_data(X, accept_sparse=\"csr\")\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = _check_sample_weight(sample_weight, X)\n",
    "\n",
    "        # Calculate neighborhood for all samples. This leaves the original\n",
    "        # point in, which needs to be considered later (i.e. point i is in the\n",
    "        # neighborhood of point i. While True, its useless information)\n",
    "        if self.metric == \"precomputed\" and sparse.issparse(X):\n",
    "            # set the diagonal to explicit values, as a point is its own\n",
    "            # neighbor\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", sparse.SparseEfficiencyWarning)\n",
    "                X.setdiag(X.diagonal())  # XXX: modifies X's internals in-place\n",
    "\n",
    "        neighbors_model = NearestNeighbors(\n",
    "            radius=self.eps,\n",
    "            algorithm=self.algorithm,\n",
    "            leaf_size=self.leaf_size,\n",
    "            metric=self.metric,\n",
    "            metric_params=self.metric_params,\n",
    "            p=self.p,\n",
    "            n_jobs=self.n_jobs,\n",
    "        )\n",
    "        neighbors_model.fit(X)\n",
    "        # This has worst case O(n^2) memory complexity\n",
    "        neighborhoods = neighbors_model.radius_neighbors(X, return_distance=False)\n",
    "\n",
    "        if sample_weight is None:\n",
    "            n_neighbors = np.array([len(neighbors) for neighbors in neighborhoods])\n",
    "        else:\n",
    "            n_neighbors = np.array(\n",
    "                [np.sum(sample_weight[neighbors]) for neighbors in neighborhoods]\n",
    "            )\n",
    "\n",
    "        # Initially, all samples are noise.\n",
    "        labels = np.full(X.shape[0], -1, dtype=np.intp)\n",
    "\n",
    "        # A list of all core samples found.\n",
    "        core_samples = np.asarray(n_neighbors >= self.min_samples, dtype=np.uint8)\n",
    "        dbscan_inner(core_samples, neighborhoods, labels)\n",
    "\n",
    "        self.core_sample_indices_ = np.where(core_samples)[0]\n",
    "        self.labels_ = labels\n",
    "\n",
    "        if len(self.core_sample_indices_):\n",
    "            # fix for scipy sparse indexing issue\n",
    "            self.components_ = X[self.core_sample_indices_].copy()\n",
    "        else:\n",
    "            # no core samples\n",
    "            self.components_ = np.empty((0, X.shape[1]))\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, X, y=None, sample_weight=None):\n",
    "        \"\"\"Compute clusters from a data or distance matrix and predict labels.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape (n_samples, n_features), or \\\n",
    "            (n_samples, n_samples)\n",
    "            Training instances to cluster, or distances between instances if\n",
    "            ``metric='precomputed'``. If a sparse matrix is provided, it will\n",
    "            be converted into a sparse ``csr_matrix``.\n",
    "        y : Ignored\n",
    "            Not used, present here for API consistency by convention.\n",
    "        sample_weight : array-like of shape (n_samples,), default=None\n",
    "            Weight of each sample, such that a sample with a weight of at least\n",
    "            ``min_samples`` is by itself a core sample; a sample with a\n",
    "            negative weight may inhibit its eps-neighbor from being core.\n",
    "            Note that weights are absolute, and default to 1.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster labels. Noisy samples are given the label -1.\n",
    "        \"\"\"\n",
    "        self.fit(X, sample_weight=sample_weight)\n",
    "        return self.labels_\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {\"pairwise\": self.metric == \"precomputed\"}\n",
    "Footer\n",
    "© 2023 GitHub, Inc.\n",
    "Footer navigation\n",
    "Terms\n",
    "Privacy\n",
    "Security\n",
    "Status\n",
    "Docs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
